python3 -m llama_cpp.server --model .model/Llama-3-ELYZA-JP-8B-q4_k_m.gguf --host 0.0.0.0 --port 8080